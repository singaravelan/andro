{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334d1f2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:05.723739Z",
     "iopub.status.busy": "2022-02-05T17:24:05.723035Z",
     "iopub.status.idle": "2022-02-05T17:24:07.144372Z",
     "shell.execute_reply": "2022-02-05T17:24:07.145261Z",
     "shell.execute_reply.started": "2022-02-05T17:23:27.122080Z"
    },
    "papermill": {
     "duration": 1.457887,
     "end_time": "2022-02-05T17:24:07.145716",
     "exception": false,
     "start_time": "2022-02-05T17:24:05.687829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader,Dataset\n",
    "from torch.utils.data import random_split\n",
    "%matplotlib inline\n",
    "\n",
    "# Use a white background for matplotlib figures\n",
    "matplotlib.rcParams['figure.facecolor'] = '#ffffff'\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a274eecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:07.185897Z",
     "iopub.status.busy": "2022-02-05T17:24:07.184965Z",
     "iopub.status.idle": "2022-02-05T17:24:12.891311Z",
     "shell.execute_reply": "2022-02-05T17:24:12.891752Z",
     "shell.execute_reply.started": "2022-02-05T17:23:28.583549Z"
    },
    "papermill": {
     "duration": 5.727414,
     "end_time": "2022-02-05T17:24:12.891927",
     "exception": false,
     "start_time": "2022-02-05T17:24:07.164513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e66890d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:12.934621Z",
     "iopub.status.busy": "2022-02-05T17:24:12.933920Z",
     "iopub.status.idle": "2022-02-05T17:24:13.080589Z",
     "shell.execute_reply": "2022-02-05T17:24:13.079964Z",
     "shell.execute_reply.started": "2022-02-05T17:23:34.761675Z"
    },
    "papermill": {
     "duration": 0.170233,
     "end_time": "2022-02-05T17:24:13.080752",
     "exception": false,
     "start_time": "2022-02-05T17:24:12.910519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_x = test_df.astype('float32')\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "test_x = test_x.values.reshape(-1,1,28,28)\n",
    "# Normalize the data\n",
    "test_x = test_x / 255.0\n",
    "test_dataset = torch.tensor(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235bd302",
   "metadata": {
    "papermill": {
     "duration": 0.017894,
     "end_time": "2022-02-05T17:24:13.118701",
     "exception": false,
     "start_time": "2022-02-05T17:24:13.100807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca909e23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:13.158265Z",
     "iopub.status.busy": "2022-02-05T17:24:13.157644Z",
     "iopub.status.idle": "2022-02-05T17:24:13.164419Z",
     "shell.execute_reply": "2022-02-05T17:24:13.164993Z",
     "shell.execute_reply.started": "2022-02-05T17:23:34.958755Z"
    },
    "papermill": {
     "duration": 0.02817,
     "end_time": "2022-02-05T17:24:13.165166",
     "exception": false,
     "start_time": "2022-02-05T17:24:13.136996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetMNIST2(Dataset):\n",
    "    \n",
    "    def __init__(self, file_path, transform=None):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # load image as ndarray type (Height * Width * Channels)\n",
    "        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n",
    "        # in this example, we use ToTensor(), so we define the numpy array like (H, W, C)\n",
    "        image = self.data.iloc[index, 1:].values.astype(np.uint8).reshape((28, 28, 1))\n",
    "        label = self.data.iloc[index, 0]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6503b791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:13.204335Z",
     "iopub.status.busy": "2022-02-05T17:24:13.203713Z",
     "iopub.status.idle": "2022-02-05T17:24:15.924771Z",
     "shell.execute_reply": "2022-02-05T17:24:15.924181Z",
     "shell.execute_reply.started": "2022-02-05T17:23:34.970091Z"
    },
    "papermill": {
     "duration": 2.741701,
     "end_time": "2022-02-05T17:24:15.924924",
     "exception": false,
     "start_time": "2022-02-05T17:24:13.183223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = DatasetMNIST2(\"/kaggle/input/digit-recognizer/train.csv\", transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b14a9d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:15.969263Z",
     "iopub.status.busy": "2022-02-05T17:24:15.968591Z",
     "iopub.status.idle": "2022-02-05T17:24:16.205881Z",
     "shell.execute_reply": "2022-02-05T17:24:16.205364Z",
     "shell.execute_reply.started": "2022-02-05T17:23:37.860174Z"
    },
    "papermill": {
     "duration": 0.262631,
     "end_time": "2022-02-05T17:24:16.206024",
     "exception": false,
     "start_time": "2022-02-05T17:24:15.943393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape: torch.Size([1, 28, 28])\n",
      "Label: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[0]\n",
    "print('image.shape:', image.shape)\n",
    "plt.imshow(image.permute(1, 2, 0), cmap='gray')\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0afd0cfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:16.248110Z",
     "iopub.status.busy": "2022-02-05T17:24:16.247172Z",
     "iopub.status.idle": "2022-02-05T17:24:16.264257Z",
     "shell.execute_reply": "2022-02-05T17:24:16.264736Z",
     "shell.execute_reply.started": "2022-02-05T17:23:38.057910Z"
    },
    "papermill": {
     "duration": 0.039666,
     "end_time": "2022-02-05T17:24:16.264908",
     "exception": false,
     "start_time": "2022-02-05T17:24:16.225242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_size = 10000\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)\n",
    "\n",
    "batch_size=128\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2973ff14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:16.306676Z",
     "iopub.status.busy": "2022-02-05T17:24:16.305717Z",
     "iopub.status.idle": "2022-02-05T17:24:16.318171Z",
     "shell.execute_reply": "2022-02-05T17:24:16.318694Z",
     "shell.execute_reply.started": "2022-02-05T17:23:38.080980Z"
    },
    "papermill": {
     "duration": 0.03491,
     "end_time": "2022-02-05T17:24:16.318855",
     "exception": false,
     "start_time": "2022-02-05T17:24:16.283945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    \"\"\"Feedfoward neural network with 1 hidden layer\"\"\"\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        # hidden layer\n",
    "        self.linear1 = nn.Linear(in_size, hidden_size)\n",
    "        # output layer\n",
    "        self.linear2 = nn.Linear(hidden_size, out_size)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        # Flatten the image tensors\n",
    "        xb = xb.view(xb.size(0), -1)\n",
    "        # Get intermediate outputs using hidden layer\n",
    "        out = self.linear1(xb)\n",
    "        # Apply activation function\n",
    "        out = F.relu(out)\n",
    "        # Get predictions using output layer\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13324f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:16.360638Z",
     "iopub.status.busy": "2022-02-05T17:24:16.359543Z",
     "iopub.status.idle": "2022-02-05T17:24:16.363946Z",
     "shell.execute_reply": "2022-02-05T17:24:16.364485Z",
     "shell.execute_reply.started": "2022-02-05T17:23:38.098579Z"
    },
    "papermill": {
     "duration": 0.026932,
     "end_time": "2022-02-05T17:24:16.364659",
     "exception": false,
     "start_time": "2022-02-05T17:24:16.337727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f77fae9",
   "metadata": {
    "papermill": {
     "duration": 0.018587,
     "end_time": "2022-02-05T17:24:16.402260",
     "exception": false,
     "start_time": "2022-02-05T17:24:16.383673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "function that can move data and model to a chosen device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "949e233a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:16.443711Z",
     "iopub.status.busy": "2022-02-05T17:24:16.442728Z",
     "iopub.status.idle": "2022-02-05T17:24:16.447068Z",
     "shell.execute_reply": "2022-02-05T17:24:16.447548Z",
     "shell.execute_reply.started": "2022-02-05T17:23:38.117214Z"
    },
    "papermill": {
     "duration": 0.026583,
     "end_time": "2022-02-05T17:24:16.447712",
     "exception": false,
     "start_time": "2022-02-05T17:24:16.421129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b228c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:16.488977Z",
     "iopub.status.busy": "2022-02-05T17:24:16.488012Z",
     "iopub.status.idle": "2022-02-05T17:24:16.492674Z",
     "shell.execute_reply": "2022-02-05T17:24:16.493122Z",
     "shell.execute_reply.started": "2022-02-05T17:23:38.126609Z"
    },
    "papermill": {
     "duration": 0.026702,
     "end_time": "2022-02-05T17:24:16.493288",
     "exception": false,
     "start_time": "2022-02-05T17:24:16.466586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a13d383f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:16.534464Z",
     "iopub.status.busy": "2022-02-05T17:24:16.533545Z",
     "iopub.status.idle": "2022-02-05T17:24:16.538504Z",
     "shell.execute_reply": "2022-02-05T17:24:16.538933Z",
     "shell.execute_reply.started": "2022-02-05T17:23:38.145902Z"
    },
    "papermill": {
     "duration": 0.026984,
     "end_time": "2022-02-05T17:24:16.539107",
     "exception": false,
     "start_time": "2022-02-05T17:24:16.512123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07ce8a6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:16.588763Z",
     "iopub.status.busy": "2022-02-05T17:24:16.588080Z",
     "iopub.status.idle": "2022-02-05T17:24:16.863586Z",
     "shell.execute_reply": "2022-02-05T17:24:16.864039Z",
     "shell.execute_reply.started": "2022-02-05T17:23:38.161023Z"
    },
    "papermill": {
     "duration": 0.306122,
     "end_time": "2022-02-05T17:24:16.864294",
     "exception": false,
     "start_time": "2022-02-05T17:24:16.558172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    images = to_device(images, device)\n",
    "    print(images.device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b328c6",
   "metadata": {
    "papermill": {
     "duration": 0.019607,
     "end_time": "2022-02-05T17:24:16.904035",
     "exception": false,
     "start_time": "2022-02-05T17:24:16.884428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc9a62d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:16.953712Z",
     "iopub.status.busy": "2022-02-05T17:24:16.953032Z",
     "iopub.status.idle": "2022-02-05T17:24:16.955275Z",
     "shell.execute_reply": "2022-02-05T17:24:16.955814Z",
     "shell.execute_reply.started": "2022-02-05T17:23:38.448601Z"
    },
    "papermill": {
     "duration": 0.030742,
     "end_time": "2022-02-05T17:24:16.955980",
     "exception": false,
     "start_time": "2022-02-05T17:24:16.925238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    \"\"\"Evaluate the model's performance on the validation set\"\"\"\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    \"\"\"Train the model using gradient descent\"\"\"\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b17dfa03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:16.999121Z",
     "iopub.status.busy": "2022-02-05T17:24:16.998499Z",
     "iopub.status.idle": "2022-02-05T17:24:17.013192Z",
     "shell.execute_reply": "2022-02-05T17:24:17.013742Z",
     "shell.execute_reply.started": "2022-02-05T17:23:38.461102Z"
    },
    "papermill": {
     "duration": 0.038208,
     "end_time": "2022-02-05T17:24:17.013909",
     "exception": false,
     "start_time": "2022-02-05T17:24:16.975701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistModel(\n",
       "  (linear1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model (on GPU)\n",
    "input_size = 784\n",
    "hidden_size = 32 # you can change this\n",
    "num_classes = 10\n",
    "\n",
    "model = MnistModel(input_size, hidden_size=hidden_size, out_size=num_classes)\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66af5ae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:17.059021Z",
     "iopub.status.busy": "2022-02-05T17:24:17.058419Z",
     "iopub.status.idle": "2022-02-05T17:24:17.060814Z",
     "shell.execute_reply": "2022-02-05T17:24:17.061285Z",
     "shell.execute_reply.started": "2022-02-05T17:23:38.483317Z"
    },
    "papermill": {
     "duration": 0.027833,
     "end_time": "2022-02-05T17:24:17.061476",
     "exception": false,
     "start_time": "2022-02-05T17:24:17.033643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    yb = model(xb)\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4bc24f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:17.106834Z",
     "iopub.status.busy": "2022-02-05T17:24:17.106212Z",
     "iopub.status.idle": "2022-02-05T17:24:19.703117Z",
     "shell.execute_reply": "2022-02-05T17:24:19.702544Z",
     "shell.execute_reply.started": "2022-02-05T17:23:38.490170Z"
    },
    "papermill": {
     "duration": 2.621861,
     "end_time": "2022-02-05T17:24:19.703265",
     "exception": false,
     "start_time": "2022-02-05T17:24:17.081404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Label = [ predict_image(test_dataset[x], model) for x in range(0,len(test_dataset)) ] \n",
    "Imageid = [ x for x in range(0,len(test_dataset)) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f1d8bdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T17:24:19.761245Z",
     "iopub.status.busy": "2022-02-05T17:24:19.760504Z",
     "iopub.status.idle": "2022-02-05T17:24:19.825271Z",
     "shell.execute_reply": "2022-02-05T17:24:19.824615Z",
     "shell.execute_reply.started": "2022-02-05T17:23:41.157063Z"
    },
    "papermill": {
     "duration": 0.101565,
     "end_time": "2022-02-05T17:24:19.825454",
     "exception": false,
     "start_time": "2022-02-05T17:24:19.723889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'Imageid': Imageid, 'Label': Label})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24.599141,
   "end_time": "2022-02-05T17:24:20.655819",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-05T17:23:56.056678",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
